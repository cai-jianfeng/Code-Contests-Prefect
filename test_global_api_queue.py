#!/usr/bin/env python3
"""
æµ‹è¯•å…¨å±€ API é˜Ÿåˆ—è´Ÿè½½å‡è¡¡çš„æ•ˆæœ
éªŒè¯å¤šä¸ª sample å¹¶è¡Œå¤„ç†æ—¶çš„ API ä½¿ç”¨åˆ†å¸ƒ
"""

import sys
import time
import threading
from collections import Counter
from unittest.mock import MagicMock, patch

from corner_case_gen_parallel import (
    ParallelProcessor, CornerCaseGenerator, SolutionValidator, 
    OpenAIClient, SandboxClient, initialize_global_api_queue,
    get_api_path, return_api_path
)
from config import ConfigManager

def test_global_api_queue_basic():
    """æµ‹è¯•å…¨å±€ API é˜Ÿåˆ—çš„åŸºæœ¬åŠŸèƒ½"""
    print("=== æµ‹è¯•å…¨å±€ API é˜Ÿåˆ—åŸºæœ¬åŠŸèƒ½ ===")
    
    api_paths = ['/api1/', '/api2/', '/api3/', '/api4/']
    initialize_global_api_queue(api_paths)
    
    # æµ‹è¯•è·å–å’Œå½’è¿˜
    api1 = get_api_path()
    api2 = get_api_path()
    print(f"è·å–åˆ° API: {api1}, {api2}")
    
    return_api_path(api1)
    return_api_path(api2)
    print("API å·²å½’è¿˜")
    
    # æµ‹è¯•è·å–æ‰€æœ‰ API
    acquired_apis = []
    for i in range(len(api_paths)):
        api = get_api_path()
        if api:
            acquired_apis.append(api)
    
    print(f"è·å–åˆ°æ‰€æœ‰ API: {acquired_apis}")
    
    # æµ‹è¯•è·å–å¤±è´¥ï¼ˆé˜Ÿåˆ—ä¸ºç©ºï¼‰
    empty_api = get_api_path(timeout=0.01)
    print(f"é˜Ÿåˆ—ä¸ºç©ºæ—¶è·å– API: {empty_api}")
    
    # å½’è¿˜æ‰€æœ‰ API
    for api in acquired_apis:
        return_api_path(api)
    print("æ‰€æœ‰ API å·²å½’è¿˜")
    print()

def test_multiple_samples_load_balancing():
    """æµ‹è¯•å¤šä¸ª sample å¹¶è¡Œå¤„ç†æ—¶çš„è´Ÿè½½å‡è¡¡"""
    print("=== æµ‹è¯•å¤šä¸ª Sample å¹¶è¡Œå¤„ç†è´Ÿè½½å‡è¡¡ ===")
    
    # API è°ƒç”¨è¿½è¸ª
    api_call_tracker = Counter()
    call_lock = threading.Lock()
    
    def mock_call_api(api_path, payload):
        # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
        time.sleep(0.03)  # 30ms å»¶è¿Ÿ
        
        # è®°å½• API è°ƒç”¨
        if "run_code" in api_path:
            base_path = api_path.replace("run_code", "").rstrip("/")
            with call_lock:
                api_call_tracker[base_path] += 1
                # æ˜¾ç¤ºå®æ—¶è°ƒç”¨æƒ…å†µ
                worker_name = threading.current_thread().name
                print(f"[{worker_name}] APIè°ƒç”¨: {base_path} (æ€»è®¡: {api_call_tracker[base_path]})")
        
        return {
            'status': 'Success',
            'run_result': {
                'stdout': f'output_{payload.get("stdin", "test")}',
                'stderr': '',
                'return_code': 0
            }
        }
    
    def mock_openai_generate(messages, model="gpt-4o", max_tokens=1000):
        """æ¨¡æ‹Ÿ OpenAI API è°ƒç”¨"""
        time.sleep(0.01)  # å¿«é€Ÿç”Ÿæˆ
        return "['test_input_1', 'test_input_2', 'test_input_3']"
    
    # åˆ›å»ºæµ‹è¯•æ ·æœ¬
    samples = []
    for i in range(4):  # 4ä¸ªæ ·æœ¬
        sample = {
            'id': f'test_sample_{i}',
            'name': f'Test Problem {i}',
            'description': f'Test problem {i} description',
            'canonical_solution': {
                'python': f'def solve_{i}(): return {i}'
            },
            'solutions': {'language': [1], 'solution': [f'def solve(): return {i}']},
            'incorrect_solutions': {'language': [1], 'solution': [f'def bad_solve(): return {-i}']}
        }
        samples.append(sample)
    
    # åˆ›å»ºé…ç½®ç®¡ç†å™¨
    config_manager = ConfigManager()
    config_manager.processing_config.sample_level_workers = 4
    config_manager.processing_config.output_generation_workers = 2
    config_manager.processing_config.solution_validation_workers = 2
    
    api_paths = ['/api1/', '/api2/', '/api3/', '/api4/']
    
    # åˆ›å»ºå¹¶è¡Œå¤„ç†å™¨
    processor = ParallelProcessor(api_paths, max_workers=2, config_manager=config_manager)
    
    # æ‰“è¡¥ä¸
    with patch.object(processor.sandbox_client, 'call_api', side_effect=mock_call_api), \
         patch.object(processor.openai_client, 'generate_corner_case', side_effect=mock_openai_generate):
        
        print(f"å¼€å§‹å¹¶è¡Œå¤„ç† {len(samples)} ä¸ªæ ·æœ¬")
        print(f"é…ç½®: sample_workers={config_manager.processing_config.sample_level_workers}")
        print(f"é…ç½®: output_workers={config_manager.processing_config.output_generation_workers}")
        print(f"ä½¿ç”¨å…¨å±€ API é˜Ÿåˆ—ç®¡ç† {len(api_paths)} ä¸ªç«¯ç‚¹")
        
        start_time = time.time()
        
        # æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è°ƒç”¨æ ¸å¿ƒé€»è¾‘ï¼‰
        results = []
        def process_sample(sample):
            try:
                corner_cases, all_results = processor.corner_case_generator.generate_for_sample(
                    sample, api_paths, 'test', max_workers=2
                )
                return sample['id'], len(corner_cases), len(all_results)
            except Exception as e:
                print(f"Error processing {sample['id']}: {e}")
                return sample['id'], 0, 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ¨¡æ‹Ÿå¹¶è¡Œå¤„ç†
        from concurrent.futures import ThreadPoolExecutor, as_completed
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(process_sample, sample) for sample in samples]
            
            for future in as_completed(futures):
                sample_id, corner_count, result_count = future.result()
                results.append((sample_id, corner_count, result_count))
        
        end_time = time.time()
        
        print(f"\nå¤„ç†å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
        
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        print("\næ ·æœ¬å¤„ç†ç»“æœ:")
        for sample_id, corner_count, result_count in results:
            print(f"  {sample_id}: {corner_count} corners, {result_count} results")
        
        # åˆ†æ API ä½¿ç”¨åˆ†å¸ƒ
        print(f"\nå…¨å±€ API è°ƒç”¨åˆ†å¸ƒ:")
        total_calls = sum(api_call_tracker.values())
        if total_calls > 0:
            for api_path, count in sorted(api_call_tracker.items()):
                percentage = (count / total_calls * 100)
                print(f"  {api_path}: {count} æ¬¡ ({percentage:.1f}%)")
            
            # è®¡ç®—è´Ÿè½½å‡è¡¡æŒ‡æ ‡
            values = list(api_call_tracker.values())
            if len(values) > 1:
                mean_val = sum(values) / len(values)
                variance = sum((x - mean_val) ** 2 for x in values) / len(values)
                balance_score = 1 / (1 + variance) if variance > 0 else 1.0
                
                print(f"\nè´Ÿè½½å‡è¡¡åˆ†æ:")
                print(f"  æœŸæœ›æ¯ä¸ª API: {total_calls / len(api_paths):.1f} æ¬¡")
                print(f"  å®é™…æ–¹å·®: {variance:.2f}")
                print(f"  å‡è¡¡åˆ†æ•°: {balance_score:.3f} (1.0ä¸ºå®Œç¾å‡è¡¡)")
                
                if balance_score > 0.8:
                    print("  âœ… å…¨å±€è´Ÿè½½å‡è¡¡è‰¯å¥½")
                elif balance_score > 0.6:
                    print("  âš ï¸  å…¨å±€è´Ÿè½½å‡è¡¡ä¸€èˆ¬")
                else:
                    print("  âŒ å…¨å±€è´Ÿè½½ä¸å‡è¡¡")
        else:
            print("  âŒ æ²¡æœ‰è®°å½•åˆ°ä»»ä½• API è°ƒç”¨")

def test_api_contention():
    """æµ‹è¯• API èµ„æºç«äº‰æƒ…å†µ"""
    print("\n=== æµ‹è¯• API èµ„æºç«äº‰ ===")
    
    api_paths = ['/api1/', '/api2/']  # åªæœ‰2ä¸ªAPI
    initialize_global_api_queue(api_paths)
    
    # ç«äº‰ç»Ÿè®¡
    contention_stats = {
        'success_immediate': 0,  # ç«‹å³è·å–æˆåŠŸ
        'success_retry': 0,      # é‡è¯•åæˆåŠŸ
        'failed': 0              # è·å–å¤±è´¥
    }
    stats_lock = threading.Lock()
    
    def worker_contention_test(worker_id: str):
        """æ¨¡æ‹Ÿå·¥ä½œçº¿ç¨‹çš„ç«äº‰æƒ…å†µ"""
        for i in range(5):  # æ¯ä¸ªå·¥ä½œçº¿ç¨‹å¤„ç†5ä¸ªä»»åŠ¡
            # å°è¯•è·å–API
            api_path = get_api_path(timeout=0.01)
            if api_path:
                with stats_lock:
                    contention_stats['success_immediate'] += 1
                print(f"Worker {worker_id} ç«‹å³è·å–åˆ° {api_path}")
                
                # æ¨¡æ‹Ÿä½¿ç”¨API
                time.sleep(0.05)
                
                # å½’è¿˜API
                return_api_path(api_path)
            else:
                print(f"Worker {worker_id} ç¬¬ä¸€æ¬¡è·å–å¤±è´¥ï¼Œç­‰å¾…é‡è¯•...")
                time.sleep(0.02)
                
                # é‡è¯•è·å–
                api_path = get_api_path(timeout=0.1)
                if api_path:
                    with stats_lock:
                        contention_stats['success_retry'] += 1
                    print(f"Worker {worker_id} é‡è¯•è·å–åˆ° {api_path}")
                    
                    # æ¨¡æ‹Ÿä½¿ç”¨API
                    time.sleep(0.05)
                    
                    # å½’è¿˜API
                    return_api_path(api_path)
                else:
                    with stats_lock:
                        contention_stats['failed'] += 1
                    print(f"Worker {worker_id} è·å–å¤±è´¥")
    
    # åˆ›å»ºå¤šä¸ªå·¥ä½œçº¿ç¨‹è¿›è¡Œç«äº‰æµ‹è¯•
    threads = []
    for i in range(6):  # 6ä¸ªå·¥ä½œçº¿ç¨‹ç«äº‰2ä¸ªAPI
        thread = threading.Thread(
            target=worker_contention_test,
            args=(f"worker_{i}",)
        )
        threads.append(thread)
    
    # å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
    start_time = time.time()
    for thread in threads:
        thread.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()
    
    end_time = time.time()
    
    print(f"\nç«äº‰æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
    print("ç«äº‰ç»Ÿè®¡:")
    print(f"  ç«‹å³è·å–æˆåŠŸ: {contention_stats['success_immediate']} æ¬¡")
    print(f"  é‡è¯•è·å–æˆåŠŸ: {contention_stats['success_retry']} æ¬¡")
    print(f"  è·å–å¤±è´¥: {contention_stats['failed']} æ¬¡")
    
    total_attempts = sum(contention_stats.values())
    if total_attempts > 0:
        success_rate = (contention_stats['success_immediate'] + contention_stats['success_retry']) / total_attempts
        print(f"  æ•´ä½“æˆåŠŸç‡: {success_rate:.2%}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 80)
    print("å…¨å±€ API é˜Ÿåˆ—è´Ÿè½½å‡è¡¡æµ‹è¯•")
    print("=" * 80)
    
    try:
        # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
        test_global_api_queue_basic()
        
        # å¤šæ ·æœ¬è´Ÿè½½å‡è¡¡æµ‹è¯•
        test_multiple_samples_load_balancing()
        
        # API ç«äº‰æµ‹è¯•
        test_api_contention()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æµ‹è¯•æ€»ç»“:")
        print("1. âœ… å…¨å±€ API é˜Ÿåˆ—åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        print("2. âœ… å¤š Sample å¹¶è¡Œå¤„ç†è´Ÿè½½å‡è¡¡è‰¯å¥½") 
        print("3. âœ… API èµ„æºç«äº‰æœºåˆ¶æœ‰æ•ˆ")
        print("4. âœ… å…¨å±€è´Ÿè½½å‡è¡¡ä¼˜åŒ–æˆåŠŸå®ç°")
        print("=" * 80)
        
        return 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
